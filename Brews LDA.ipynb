{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "343d4bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "Collecting scipy>=1.7.0\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\phili\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Installing collected packages: smart-open, scipy, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.6.2\n",
      "    Uninstalling scipy-1.6.2:\n",
      "      Successfully uninstalled scipy-1.6.2\n",
      "Successfully installed gensim-4.3.2 scipy-1.10.1 smart-open-6.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40d0a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.033*\"good\" + 0.029*\"food\" + 0.024*\"not\" + 0.021*\"t\" + 0.020*\"beer\" + 0.016*\"pizza\" + 0.014*\"that\" + 0.014*\"s\" + 0.013*\"really\" + 0.013*\"like\"'),\n",
       " (1,\n",
       "  '0.062*\"we\" + 0.027*\"our\" + 0.025*\"were\" + 0.018*\"us\" + 0.016*\"had\" + 0.013*\"at\" + 0.013*\"she\" + 0.012*\"my\" + 0.012*\"t\" + 0.011*\"that\"'),\n",
       " (2,\n",
       "  '0.037*\"ve\" + 0.035*\"been\" + 0.034*\"my\" + 0.029*\"have\" + 0.023*\"here\" + 0.021*\"this\" + 0.020*\"time\" + 0.019*\"always\" + 0.018*\"best\" + 0.018*\"are\"'),\n",
       " (3,\n",
       "  '0.053*\"brunch\" + 0.018*\"coffee\" + 0.014*\"vegan\" + 0.014*\"eggs\" + 0.013*\"delicious\" + 0.012*\"so\" + 0.011*\"hummus\" + 0.011*\"dessert\" + 0.011*\"you\" + 0.009*\"sunday\"'),\n",
       " (4,\n",
       "  '0.052*\"great\" + 0.028*\"place\" + 0.027*\"food\" + 0.024*\"good\" + 0.024*\"beer\" + 0.021*\"very\" + 0.019*\"this\" + 0.019*\"we\" + 0.016*\"back\" + 0.016*\"were\"'),\n",
       " (5,\n",
       "  '0.029*\"that\" + 0.023*\"you\" + 0.019*\"t\" + 0.017*\"this\" + 0.016*\"they\" + 0.015*\"s\" + 0.012*\"not\" + 0.011*\"my\" + 0.010*\"be\" + 0.010*\"me\"'),\n",
       " (6,\n",
       "  '0.021*\"were\" + 0.020*\"had\" + 0.019*\"burger\" + 0.017*\"cheese\" + 0.016*\"my\" + 0.016*\"fries\" + 0.015*\"on\" + 0.013*\"good\" + 0.013*\"chicken\" + 0.012*\"they\"'),\n",
       " (7,\n",
       "  '0.016*\"as\" + 0.016*\"we\" + 0.014*\"my\" + 0.013*\"were\" + 0.013*\"on\" + 0.011*\"which\" + 0.009*\"that\" + 0.008*\"had\" + 0.008*\"an\" + 0.008*\"from\"'),\n",
       " (8,\n",
       "  '0.026*\"you\" + 0.023*\"they\" + 0.019*\"have\" + 0.017*\"s\" + 0.016*\"are\" + 0.016*\"on\" + 0.015*\"beer\" + 0.014*\"there\" + 0.012*\"place\" + 0.011*\"bar\"'),\n",
       " (9,\n",
       "  '0.038*\"beer\" + 0.030*\"beers\" + 0.025*\"their\" + 0.023*\"brewery\" + 0.017*\"on\" + 0.016*\"they\" + 0.013*\"ipa\" + 0.011*\"my\" + 0.009*\"had\" + 0.009*\"as\"')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_punctuation, strip_numeric\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import gensim\n",
    "\n",
    "# Preprocessing the text data\n",
    "data = pd.read_csv(r'C:\\Users\\phili\\Downloads\\merged_data.csv')\n",
    "\n",
    "# Custom filter to remove punctuation and numeric characters\n",
    "custom_filters = [lambda x: x.lower(), strip_punctuation, strip_numeric]\n",
    "\n",
    "# Apply preprocessing to each document in the text column\n",
    "processed_docs = [preprocess_string(doc, custom_filters) for doc in data['text']]\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = Dictionary(processed_docs)\n",
    "\n",
    "# Filter out extremes to remove too rare or too common words\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "# Convert document into the bag-of-words (BoW) format\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Training the LDA model\n",
    "# Using 10 topics as an example\n",
    "lda_model = LdaModel(corpus, num_topics=10, id2word=dictionary, passes=10)\n",
    "\n",
    "# Extract the words and their weights for each topic\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459894c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "  Most Impactful: [('good', 0.033091985), ('food', 0.029058008), ('not', 0.023974163), ('t', 0.021299744), ('beer', 0.019742806), ('pizza', 0.015662752), ('that', 0.014423424), ('s', 0.014103242), ('really', 0.013232016), ('like', 0.013023522)]\n",
      "  Least Impactful: []\n",
      "\n",
      "\n",
      "Topic 1:\n",
      "  Most Impactful: [('we', 0.06158882), ('our', 0.026781134), ('were', 0.025471117), ('us', 0.01790044), ('had', 0.016279588), ('at', 0.013036208), ('she', 0.01268147), ('my', 0.0119477855), ('t', 0.011570202), ('that', 0.011219331)]\n",
      "  Least Impactful: []\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "  Most Impactful: [('ve', 0.036889236), ('been', 0.03452868), ('my', 0.034296367), ('have', 0.02897691), ('here', 0.022974644), ('this', 0.021006577), ('time', 0.01982171), ('always', 0.019248096), ('best', 0.01757086), ('are', 0.01752876)]\n",
      "  Least Impactful: []\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "  Most Impactful: [('brunch', 0.05289516), ('coffee', 0.01767959), ('vegan', 0.014429281), ('eggs', 0.013971929), ('delicious', 0.012632333), ('so', 0.011589699), ('hummus', 0.01121916), ('dessert', 0.011162751), ('you', 0.010511835), ('sunday', 0.009365504)]\n",
      "  Least Impactful: []\n",
      "\n",
      "\n",
      "Topic 4:\n",
      "  Most Impactful: [('great', 0.052471604), ('place', 0.027739085), ('food', 0.02665177), ('good', 0.024493583), ('beer', 0.024232315), ('very', 0.021485802), ('this', 0.019036116), ('we', 0.01902909), ('back', 0.016387606), ('were', 0.015660219)]\n",
      "  Least Impactful: []\n",
      "\n",
      "\n",
      "Topic 5:\n",
      "  Most Impactful: [('that', 0.028528227), ('you', 0.022925401), ('t', 0.018724715), ('this', 0.017136702), ('they', 0.015784346), ('s', 0.014923444), ('not', 0.012168539), ('my', 0.0110644195), ('be', 0.010491986), ('me', 0.010433882)]\n",
      "  Least Impactful: []\n",
      "\n",
      "\n",
      "Topic 6:\n",
      "  Most Impactful: [('were', 0.020535044), ('had', 0.02023464), ('burger', 0.018664377), ('cheese', 0.01726469), ('my', 0.016414184), ('fries', 0.01607539), ('on', 0.014587118), ('good', 0.013180268), ('chicken', 0.012663052), ('they', 0.011996516)]\n",
      "  Least Impactful: []\n",
      "\n",
      "\n",
      "Topic 7:\n",
      "  Most Impactful: [('as', 0.016056998), ('we', 0.015503063), ('my', 0.013652703), ('were', 0.013295518), ('on', 0.013148066), ('which', 0.011020669), ('that', 0.008903401), ('had', 0.008069261), ('an', 0.008037727), ('from', 0.007718346)]\n",
      "  Least Impactful: []\n",
      "\n",
      "\n",
      "Topic 8:\n",
      "  Most Impactful: [('you', 0.025884263), ('they', 0.02267964), ('have', 0.018672472), ('s', 0.016891023), ('are', 0.016137358), ('on', 0.015675591), ('beer', 0.01511243), ('there', 0.014100695), ('place', 0.011657164), ('bar', 0.010590272)]\n",
      "  Least Impactful: []\n",
      "\n",
      "\n",
      "Topic 9:\n",
      "  Most Impactful: [('beer', 0.037915643), ('beers', 0.02993504), ('their', 0.02467828), ('brewery', 0.0229292), ('on', 0.016938448), ('they', 0.016243095), ('ipa', 0.012550167), ('my', 0.011149782), ('had', 0.009199608), ('as', 0.008640501)]\n",
      "  Least Impactful: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_topics = 10  # or however many topics we want\n",
    "num_words = 10   # the number of words to retrieve for most and least impactful\n",
    "\n",
    "# Function to get the most and least impactful words for each topic\n",
    "def get_topic_words(lda_model, num_topics, num_words):\n",
    "    topic_words = {}\n",
    "\n",
    "    for topic_id in range(num_topics):\n",
    "        # Most impactful words\n",
    "        top_words = lda_model.show_topic(topic_id, topn=num_words)\n",
    "        # Check if the word IDs or word strings are returned\n",
    "        if top_words and isinstance(top_words[0][0], int):\n",
    "            top_words = [(dictionary[word_id], weight) for word_id, weight in top_words]\n",
    "        else:\n",
    "            top_words = [(word, weight) for word, weight in top_words]\n",
    "\n",
    "        # Least impactful words\n",
    "        bottom_words = lda_model.show_topic(topic_id, topn=-num_words)\n",
    "        # Check if the word IDs or word strings are returned and if bottom_words is not empty\n",
    "        if bottom_words and isinstance(bottom_words[0][0], int):\n",
    "            bottom_words = [(dictionary[word_id], weight) for word_id, weight in bottom_words]\n",
    "        elif bottom_words:\n",
    "            bottom_words = [(word, weight) for word, weight in bottom_words]\n",
    "        else:\n",
    "            bottom_words = []\n",
    "\n",
    "        topic_words[topic_id] = {'Most Impactful': top_words, 'Least Impactful': bottom_words}\n",
    "\n",
    "    return topic_words\n",
    "\n",
    "# Retrieve the words\n",
    "topic_words = get_topic_words(lda_model, num_topics, num_words)\n",
    "\n",
    "# Print the results\n",
    "for topic, words in topic_words.items():\n",
    "    print(f\"Topic {topic}:\")\n",
    "    print(\"  Most Impactful:\", words['Most Impactful'])\n",
    "    print(\"  Least Impactful:\", words['Least Impactful'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50992075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Least impactful words: [('oushe', 4.866634e-07), ('atar', 4.8666305e-07), ('meshwi', 4.866627e-07), ('fatar', 4.8666266e-07), ('disrespectful', 4.866624e-07), ('labneh', 4.8666203e-07), ('tia', 4.86662e-07), ('chapman', 4.8666146e-07), ('cashews', 4.8666107e-07), ('guides', 4.8666055e-07)]\n",
      "Topic 1: Least impactful words: [('kouign', 2.4866264e-07), ('labne', 2.4866262e-07), ('herbal', 2.486626e-07), ('croissant', 2.486625e-07), ('turmeric', 2.4866247e-07), ('shish', 2.4866222e-07), ('taouk', 2.4866208e-07), ('hanger', 2.4866202e-07), ('richness', 2.4866185e-07), ('manoushe', 2.486617e-07)]\n",
      "Topic 2: Least impactful words: [('tehina', 8.9983564e-07), ('comp', 8.998354e-07), ('kebab', 8.998353e-07), ('gravlax', 8.998352e-07), ('atar', 8.9983416e-07), ('chickpea', 8.9983416e-07), ('scared', 8.998331e-07), ('labne', 8.998326e-07), ('maibock', 8.998323e-07), ('ipad', 8.998277e-07)]\n",
      "Topic 3: Least impactful words: [('koelschip', 2.3026198e-06), ('christian', 2.3026198e-06), ('racist', 2.3026196e-06), ('elena', 2.3026194e-06), ('iu', 2.3026194e-06), ('hoppin', 2.3026194e-06), ('cats', 2.3026194e-06), ('yelled', 2.3026194e-06), ('clustertruck', 2.3026194e-06), ('tournament', 2.3026194e-06)]\n",
      "Topic 4: Least impactful words: [('muhammara', 5.454123e-07), ('atar', 5.4541215e-07), ('parsley', 5.4541107e-07), ('djej', 5.4541096e-07), ('molasses', 5.454109e-07), ('taouk', 5.454107e-07), ('shish', 5.454105e-07), ('uninspired', 5.4541033e-07), ('inches', 5.4541005e-07), ('mia', 5.4540993e-07)]\n",
      "Topic 5: Least impactful words: [('tehina', 2.0779468e-07), ('oushe', 2.0779463e-07), ('labneh', 2.0779443e-07), ('muhammara', 2.077944e-07), ('taouk', 2.0779433e-07), ('tabouleh', 2.077943e-07), ('harra', 2.0779426e-07), ('atar', 2.0779414e-07), ('shish', 2.0779406e-07), ('labne', 2.0779393e-07)]\n",
      "Topic 6: Least impactful words: [('clustertruck', 3.8733293e-07), ('manoushe', 3.873329e-07), ('oushe', 3.873329e-07), ('suraya', 3.873328e-07), ('charities', 3.8733256e-07), ('labneh', 3.8733242e-07), ('lattes', 3.8733214e-07), ('maude', 3.87332e-07), ('magpie', 3.8733194e-07), ('legged', 3.8733165e-07)]\n",
      "Topic 7: Least impactful words: [('records', 6.8063815e-07), ('coleslaw', 6.8063775e-07), ('proceed', 6.806369e-07), ('bingo', 6.806363e-07), ('unremarkable', 6.8063576e-07), ('maude', 6.806352e-07), ('anybody', 6.806326e-07), ('christian', 6.8062496e-07), ('participated', 6.806223e-07), ('hoppin', 6.8062207e-07)]\n",
      "Topic 8: Least impactful words: [('kafta', 2.36374e-07), ('shish', 2.36374e-07), ('labneh', 2.36374e-07), ('ganoush', 2.3637399e-07), ('tabouleh', 2.3637398e-07), ('fatteh', 2.3637395e-07), ('sayf', 2.3637392e-07), ('mezza', 2.3637392e-07), ('abu', 2.3637391e-07), ('manoushe', 2.3637381e-07)]\n",
      "Topic 9: Least impactful words: [('kouign', 6.225413e-07), ('atar', 6.225413e-07), ('branzino', 6.225413e-07), ('gravlax', 6.225412e-07), ('labneh', 6.225412e-07), ('harra', 6.225412e-07), ('ghanoush', 6.2254117e-07), ('tabouleh', 6.2254117e-07), ('shish', 6.2254117e-07), ('yellowtail', 6.225411e-07)]\n"
     ]
    }
   ],
   "source": [
    "for topic_id in range(num_topics):\n",
    "    # Get all words and weights for a topic\n",
    "    all_words = lda_model.show_topic(topic_id, topn=len(dictionary))\n",
    "\n",
    "    # Select a threshold or simply pick words from the lower end of the list\n",
    "    # For example, picking the last 'num_words' words in the list\n",
    "    least_impactful_words = all_words[-num_words:]\n",
    "\n",
    "    print(f\"Topic {topic_id}: Least impactful words:\", least_impactful_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
